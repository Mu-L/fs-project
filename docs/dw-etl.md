# Data Warehouse Extract Transform Load

数据仓库分层设计和清洗方案

## 分层设计

### ODS层
- 数据来源：通过Flink CDC等方式采集业务数据。
- 存储服务：Kafka消息队列，保存CDC日志。

### DWD层（全量业务原数据）
- 数据来源：ODS层的Kafka消息队列；通过业务端全量初始化。
- 存储服务：Mongo，按表存储，按主键拆分集合或分片。
- 处理方式：保留原格式和全量历史数据，不做任何特殊处理。

### DWB层（清洗后的基础数据）
- 数据来源：ODS层的Kafka消息队列；通过DWD层全量初始化。
- 存储服务：Mongo按主键拆分集合或分片。
- 处理方式：按主体存储，含字典和明细，去除冗余属性和非查询展示字段。
- 注意事项：对需要保持历史状态的属性，如业务发生时的用户名称等，需留痕不去除；主键字段以真实外键为准。

### DWS层（大宽表，预聚合）
- 数据来源：ODS层的Kafka消息队列；DWB层的主体信息。
- 存储服务：Mongo，大宽表，预聚合，按时间拆分集合或分片；可CDC同步到ClickHouse中。
- 明细表处理方式：通过订阅ODS层的变更，读取明细数据关联的DWB层外键信息，组合成大宽表。
- 预聚合处理方式：通过定时任务，优先按照日期进行上卷，同时根据外键补充可用于筛选的关联属性。
- 注意事项：关联信息可通过外键在应用程序中进行组装，非必要不进行冗余；依照数据量控制上卷层级。

### ADS层
- 数据来源：ODS层的Kafka消息队列；DWB层的主体信息。
- 存储服务：Mongo/Elasticsearch/Redis/HBase等，偏重于单记录查询。
- 处理方式：按业务规则组织数据，生成用户画像、实时统计等信息。


## 处理流程

### DWD层初始化
- 建议按主键排序，小批量循环，一对一同步业务端数据。
- 需控制好读取和写入并发，设置合适的分页大小和并发线程。

### DWD层增量
- 建议按业务端原格式保存全量历史数据。
- 数据清洗和格式化，不在DWD层处理，避免破坏原数据和内聚原则。

### DWB层
- 配置信息：基础表、表主键、表字段、分区规则；清洗规则。
- 报表属性：外键关系。
- 本层表为业务表的字段子集，去除冗余，数据量与业务端一致。

### DWS层
- 配置信息：宽表、表主键、表字段、分区规则；预聚合规则。
- 报表属性：维度字段、度量字段；组或集引用。
- 通过DWB层完成上卷和拓展外键属性，可在一次计算中生成多层上卷结果，避免计算任务依赖。
- 增量预聚合时，通过时间筛选明细数据，由程序提取外键后批量拉取关联记录，并在内存中完成组装计算。


## 最佳实践

### 数据报表
- 通过DWS层大宽表进行单表聚合查询，由程序通过外键组装DWB层的关联信息，避免在库中进行联表查询。
- 若采用ClickHouse按时间分区，在报表查询时应尽可能命中时间分区字段。
- 报表界面的筛选字段，如用户名称等，可通过DWB层获取。
- 避免在DWS层做过多的预聚合，可通过组、集等方式，在程序中进行二次处理。

### 业务支撑
- 支持ADS层和DWB层的主键查询，可单次查询多条记录，不支持分页。
- 支持DWB层单表明细查询，可在程序中组装外键属性，不支持联表查询。
- 其他查询可查考数据报表，也可将ADS层数据推送到业务端。
- 由于ClickHouse可能采用异步写入，对实时性和事务性要求较高的业务，建议走Mongo查询。

## Q&A

### 多个时间字段的大宽表如何处理？
可设置二级索引，将非分区的时间字段查询，转换为分区时间字段查询以提高查询效率，同时保持原时间字段的筛选逻辑。
分区时间字段要求记录创建时必须存在，且不能修改，建议为业务的首次发生时间。

### 若需要根据多个维度分别获取统计结果，是否需要在DWS中提供预聚合表？
若明细数据量较小，或通过日期等维度上卷之后将数据量降低到可接受的程度，则仅提供明细表，业务端所需的最终结果，通过程序查询DWS层大宽表进行二次聚合获取。
即遵照雪花模型，避免进行过多的预聚合，导致资源浪费、维护困难。若性能受限，必须要进行更细维度的预聚合，建议通过程序按规则自动生成，避免增加手动开发的工作量。

### 多个业务子系统之间的事务型数据，是否可通过数仓进行获取？
子系统之间的事务数据，即写入后需要立即读取的，建议通过微服务间的RPC调用访问对应业务子系统获取。

### 对于历史数据可能发生变更，且查询频率不确定的统计报表，应该怎么处理？
针对此类需求，不建议提前进行预聚合，可在查询时提交计算任务，排队等待，在异步处理完成后发送查询通知。

